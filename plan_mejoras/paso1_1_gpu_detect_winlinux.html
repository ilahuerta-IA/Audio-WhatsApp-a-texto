<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detalle Paso 1.1: Detección GPU y Entorno (Win/Linux)</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <h3>Sub-Detalle Paso 1.1: Detección de GPU NVIDIA y Preparación del Entorno (Windows/Linux)</h3>
        <p><strong>Objetivo Específico:</strong> Determinar si hay una GPU NVIDIA usable (CUDA) y asegurar que el entorno Python tiene instalada la versión correcta de PyTorch para poder aprovecharla.</p>
        <p><strong>Método:</strong> Combinar la verificación externa (`nvidia-smi`) con la instalación y verificación interna de PyTorch.</p>
        <p><strong>Estado:</strong> <span class="status status-completo">Completado</span></p>>

        <h4>Proceso Conceptual Detallado:</h4>
        <ol class="detalle-pasos">
            <li>
                <strong>1.1.1: Verificar Prerrequisito - Drivers NVIDIA y `nvidia-smi`</strong>
                - Confirmar que los drivers oficiales de NVIDIA están instalados en el sistema.
                - Validar que la utilidad `nvidia-smi` es accesible desde la línea de comandos (está en el PATH).
                <p class="nota">Este es el primer indicativo externo de la presencia de hardware y software base de NVIDIA.</p>
            </li>
            <li>
                <strong>1.1.2: Intento de Ejecución de `nvidia-smi` desde Python (Detección Preliminar)</strong>
                - Implementar lógica en Python (ej: en `utils.py` o `main.py` durante el inicio) para ejecutar `nvidia-smi` usando `subprocess`.
                - Capturar si la ejecución fue exitosa (código de retorno 0) o fallida.
                <p class="nota">Un éxito aquí sugiere fuertemente la disponibilidad de CUDA, pero no lo garantiza para PyTorch aún.</p>
            </li>
            <li>
                <strong>1.1.3: Determinar la Instalación Necesaria de PyTorch</strong>
                - **Si `nvidia-smi` funcionó:** El objetivo es usar la versión de PyTorch con soporte CUDA.
                - **Si `nvidia-smi` falló:** Solo se puede usar la versión de PyTorch para CPU.
                <p class="nota">La decisión sobre qué versión de PyTorch instalar/verificar depende del resultado anterior.</p>
            </li>
            <li>
                <strong>1.1.4: Gestionar Instalación de PyTorch (Acción Clave del Entorno)</strong>
                - **Instrucción Crucial:** La versión correcta de PyTorch (CPU o CUDA específica) DEBE ser instalada en el entorno virtual (`venv`) del proyecto.
                - **Cómo Obtener el Comando:** Dirigir al desarrollador/usuario a la página oficial de PyTorch (<a href="https://pytorch.org/get-started/locally/" target="_blank">pytorch.org/get-started/locally/</a>). Allí se selecciona OS (Linux/Windows), gestor de paquetes (pip), lenguaje (Python) y **Compute Platform (CUDA versión X.Y o CPU)**. La web generará el comando `pip install ...` exacto.
                - **Cuándo Instalar:** Esto generalmente se hace UNA VEZ al configurar el entorno de desarrollo/ejecución, no dinámicamente cada vez que corre la app. Se debe asegurar que `requirements.txt` refleje la versión deseada (CPU o CUDA).
                <p class="nota">Instalar simplemente `pip install torch` a menudo instala la versión CPU. Para CUDA, se requiere el comando específico de la web oficial.</p>
            </li>
            <li>
                <strong>1.1.5: Verificación Definitiva con PyTorch (Dentro de Python)</strong>
                - Una vez instalado PyTorch (versión CPU o CUDA), añadir código en Python para verificar programáticamente si CUDA está disponible *para PyTorch*:
                  ```python
                  # Concepto (no código final)
                  import torch
                  cuda_disponible = torch.cuda.is_available()
                  ```
                - Esta llamada (`torch.cuda.is_available()`) es la confirmación final. Puede devolver `False` incluso si `nvidia-smi` funciona, si la versión de PyTorch instalada no coincide con los drivers CUDA o es la versión CPU.
            </li>
             <li>
                <strong>1.1.6: Establecer Dispositivo Lógico para la Aplicación</strong>
                - Basándose en el resultado de `torch.cuda.is_available()`:
                    - Si es `True`: Se establece el dispositivo interno como `'cuda'`.
                    - Si es `False`: Se establece el dispositivo interno como `'cpu'`, independientemente del resultado de `nvidia-smi`.
                - Este valor (`'cuda'` o `'cpu'`) será el que se pase finalmente a Whisper (y potencialmente otras librerías).
            </li>
        </ol>
        <p><strong>Conclusión del Paso 1.1:</strong> Al finalizar este paso, la aplicación sabrá si puede usar CUDA (`'cuda'`) o debe recurrir a CPU (`'cpu'`), y se asume que el entorno Python ya tiene instalada la versión de PyTorch correspondiente a esa capacidad detectada y verificada.</p>

        <a href="bloque1_whisper.html" class="nav-back">← Volver al Bloque 1</a>
    </div>
</body>
</html>